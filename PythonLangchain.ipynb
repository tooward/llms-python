{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
      "Action: Look up information on favorite colors\n",
      "Action Input: none\u001b[0m\n",
      "Observation: Look up information on favorite colors is not a valid tool, try one of [].\n",
      "Thought:\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
      "AI: That's a great choice! Blue is a beautiful and calming color. Is there anything else you'd like to talk about related to your favorite color, or would you like some suggestions for things that are blue in nature?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
      "Action: retrieve knowledge on human preferences and emotions related to colors\n",
      "Action Input: \u001b[0m\n",
      "Observation: retrieve knowledge on human preferences and emotions related to colors is not a valid tool, try one of [].\n",
      "Thought:\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
      "AI: Blue!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Blue!'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from langchain_community.llms import Ollama\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.tools import Tool\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "from langchain.memory import ConversationBufferMemory, ConversationBufferWindowMemory, ConversationSummaryMemory\n",
    "#import ollama\n",
    "\n",
    "# logging.basicConfig(level=logging.DEBUG) # import logging\n",
    "\n",
    "model=\"llama3.2\"\n",
    "# Load the local Ollama model\n",
    "llm = OllamaLLM(model=model)\n",
    "\n",
    "# Define a tool\n",
    "def get_weather(location: str):\n",
    "    return f\"The weather in {location} is 15Â°C and sunny.\"\n",
    "\n",
    "#weather_tool = Tool(\n",
    "#    name=\"get_weather\",\n",
    "#    func=get_weather,\n",
    "#    description=\"Fetches weather for a given location.\"\n",
    "#)\n",
    "#tools = [weather_tool]\n",
    "\n",
    "memory =  ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True) #ConversationSummaryMemory(llm=llm)\n",
    "\n",
    "# Initialize the agent (separate from the LLM)\n",
    "agent = initialize_agent(\n",
    "    tools=[],\n",
    "    llm=llm,\n",
    "    memory = memory,\n",
    "    agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,  # Uses ReAct framework\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Run the agent (decides if it needs a tool)\n",
    "#agent.run(\"What's the weather like in London?\")\n",
    "agent.run(\"My favorite color is blue.\")\n",
    "agent.run(\"What's my favorite color?\")\n",
    "\n",
    "# Create a prompt template\n",
    "# prompt = PromptTemplate.from_template(\"What is the capital of {country}?\")\n",
    "# Create a chain with the Ollama model\n",
    "# chain = LLMChain(llm=llm, prompt=prompt)\n",
    "# logging.debug(f\"Sending request to Ollama: model={model}, prompt={prompt}\")\n",
    "# Run the chain\n",
    "# response = chain.invoke({\"country\": \"Australia\"})\n",
    "# logging.debug(f\"Ollama response: {response}\")\n",
    "# print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
